{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python -m venv venv`\n",
    "\n",
    "`.\\venv\\Scripts\\activate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../files/titanic3.xls\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions\n",
    "df.info()\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the title for each person\n",
    "def find_title(name):\n",
    "    strings = name.split()\n",
    "    for string in strings:\n",
    "        if string.endswith('.'):\n",
    "            return string\n",
    "        \n",
    "    return None\n",
    "df['title'] = df['name'].apply(find_title)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_avg_age = df.groupby('title')['age'].mean()\n",
    "# Fill in missing ages based on title with the average age\n",
    "df = df.merge(title_avg_age, on='title', suffixes=('', '_avg'))\n",
    "df['age'].fillna(df['age_avg'], inplace=True)\n",
    "df.drop(columns=['age_avg'], inplace=True)\n",
    "\n",
    "print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in average fare with total average\n",
    "avg_fare = df['fare'].mean()\n",
    "\n",
    "df['fare'].fillna(avg_fare, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['cabin'] = df['cabin'].fillna('X')\n",
    "\n",
    "# df['cabin'] = df['cabin'].apply(lambda x: str(x)[0])\n",
    "\n",
    "df['embarked'] = df['embarked'].fillna('X')\n",
    "\n",
    "df['home.dest'] = df['home.dest'].fillna('X')\n",
    "\n",
    "home_value_counts = df['home.dest'].value_counts()\n",
    "print(home_value_counts)\n",
    "\n",
    "# cabin_value_counts = df['cabin'].value_counts()\n",
    "# print(cabin_value_counts)\n",
    "\n",
    "\n",
    "\n",
    "embarking_value_counts = df['embarked'].value_counts()\n",
    "print(embarking_value_counts)\n",
    "\n",
    "# df['embarked'] = df[embarking_value_counts[0]]\n",
    "\n",
    "# embarking_value_counts = df['embarked'].value_counts()\n",
    "\n",
    "# print(embarking_value_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if someone had a cabin\n",
    "df['is_cabin'] = df['cabin'].isnull()\n",
    "df.drop(['cabin'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions\n",
    "df.info()\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "print(df['embarked'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the sex\n",
    "df['sex'] = df['sex'].astype('category')\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "df_encoded =  enc.fit_transform(df[['sex']])\n",
    "sex_encoded_df = pd.DataFrame.sparse.from_spmatrix(df_encoded, columns=enc.get_feature_names_out(['sex']))\n",
    "\n",
    "df = pd.concat([df, sex_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the embarking location\n",
    "df['embarked'] = df['embarked'].astype('category')\n",
    "\n",
    "df_encoded =  enc.fit_transform(df[['embarked']])\n",
    "embarked_encoded_df = pd.DataFrame.sparse.from_spmatrix(df_encoded, columns=enc.get_feature_names_out(['embarked']))\n",
    "\n",
    "df = pd.concat([df, embarked_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #encode the Title \n",
    "# df['title'] = df['title'].astype('category')\n",
    "\n",
    "# df_encoded =  enc.fit_transform(df[['title']])\n",
    "# title_encoded_df = pd.DataFrame.sparse.from_spmatrix(df_encoded, columns=enc.get_feature_names_out(['title']))\n",
    "\n",
    "# df = pd.concat([df, title_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('sex', axis=1)\n",
    "df = df.drop('embarked', axis=1)\n",
    "# df = df.drop('title', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin making the model\n",
    "# split the data\n",
    "feature_cols = df.columns.tolist()\n",
    "feature_cols.remove('survived')\n",
    "feature_cols.remove('name')\n",
    "feature_cols.remove('body')\n",
    "feature_cols.remove('boat')\n",
    "feature_cols.remove('ticket')\n",
    "feature_cols.remove('home.dest')\n",
    "feature_cols.remove('title')\n",
    "\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['survived']\n",
    "\n",
    "print(feature_cols)\n",
    "#Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 70% training and 30% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check contents of X\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print contents of y\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=1001, max_leaf_nodes=16, n_jobs=1)\n",
    "clf_lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "clf_rf = clf_rf.fit(X_train, y_train)\n",
    "clf_lr = clf_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = clf_rf.predict(X_test)\n",
    "\n",
    "print(\"rf accuracy:\", metrics.accuracy_score(y_test, rf_y_pred))\n",
    "\n",
    "#random forest confusion matrix\n",
    "\n",
    "rf_cm = confusion_matrix(y_test, rf_y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=rf_cm, display_labels=np.unique(y))\n",
    "\n",
    "disp.plot()\n",
    "plt.title(\"Random Forest Classifier Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y_pred = clf_lr.predict(X_test)\n",
    "\n",
    "print(\"lr accuracy:\", metrics.accuracy_score(y_test, lr_y_pred))\n",
    "\n",
    "#lr confusion matrix\n",
    "\n",
    "lr_cm = confusion_matrix(y_test, lr_y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=lr_cm, display_labels=np.unique(y))\n",
    "\n",
    "disp.plot()\n",
    "plt.title(\"Logistic Regression Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create normalized Confusion Matrix\n",
    "rf_cm_normalized = rf_cm.astype('float') / rf_cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(rf_cm_normalized, annot=True, linewidths = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create normalized Confusion Matrix\n",
    "lr_cm_normalized = lr_cm.astype('float') / lr_cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(lr_cm_normalized, annot=True, linewidths = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
